{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "different-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model    import *\n",
    "from sklearn.metrics         import mean_squared_error\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection  import RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "incident-flashing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "# upload data into pandas df - no missing values, all categorical vars are numerical \n",
    "heart = pd.read_csv('https://github.com/danny-carrera/ml_lab_project_dcarrera/blob/main/heart.csv')\n",
    "heart.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "brutal-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features and target\n",
    "y = heart['target']\n",
    "X = heart.drop(columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "naughty-lodging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 13)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "comprehensive-medicare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 13)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure that all features contain enough variance to be predictive - none dropped\n",
    "sel = VarianceThreshold(threshold=(.9 * (1 - .0)))\n",
    "sel.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "floating-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test set \n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "photographic-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and validation set\n",
    "X_train, X_valid, y_train, y_valid= train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "numeric-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers im interested in checking out\n",
    "classifiers = [LogisticRegression(), \\\n",
    "               GaussianNB(), \\\n",
    "               tree.DecisionTreeClassifier(), \\\n",
    "               RandomForestClassifier(), \\\n",
    "               GradientBoostingClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "incorrect-prediction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() 0.7894736842105263\n",
      "GaussianNB() 0.8026315789473685\n",
      "DecisionTreeClassifier() 0.7368421052631579\n",
      "RandomForestClassifier() 0.8421052631578947\n",
      "GradientBoostingClassifier() 0.8026315789473685\n"
     ]
    }
   ],
   "source": [
    "# try out a few classifier with default parameters and standardized data\n",
    "for model in classifiers:\n",
    "    \n",
    "    pipe = Pipeline([('scalar', StandardScaler()),\n",
    "                     ('clf', model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_valid)\n",
    "    accuracy = accuracy_score(y_valid, y_pred)\n",
    "    print(model, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-adventure",
   "metadata": {},
   "source": [
    "Based on accuracy results above, I will move foward with Logistic Regression, Gradient Boosting Classifier, and Random Forest and try to improve from their baseline performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "mexican-hurricane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=11, n_estimators=40)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define models and their parameters to be considered\n",
    "search_space = [\n",
    "                 {'clf': [RandomForestClassifier()], # Actual Estimator\n",
    "                 'clf__n_estimators' : list(range(10,101,10)), # of trees\n",
    "                 'clf__max_features' : list(range(6,32,5)), # of features to consider for split\n",
    "                 'clf__min_samples_leaf' : list(range(1,7,2))}, # of min samples allowed per leaf\n",
    "                \n",
    "                {'clf': [LogisticRegression()],\n",
    "                 'clf__penalty': ['l1', 'l2'],\n",
    "                 'clf__C': np.logspace(0, 4, 10)},\n",
    "               \n",
    "                {'clf': [GradientBoostingClassifier()],\n",
    "                'clf__learning_rate': [1, 0.5, 0.25, 0.1, 0.05, 0.01],\n",
    "                'clf__n_estimators' : [1, 2, 4, 8, 16, 32, 64, 100, 200]}] # of trees\n",
    "\n",
    "# Use Random Search to go through models and different combinations of their parameters listed above\n",
    "clf_algos_rand = RandomizedSearchCV(estimator=pipe, \n",
    "                                    param_distributions=search_space, \n",
    "                                    n_iter=25,\n",
    "                                    cv=5, \n",
    "                                    n_jobs=-1,\n",
    "                                    verbose=1)\n",
    "\n",
    "\n",
    "# get best model from Random Search\n",
    "best_model = clf_algos_rand.fit(X_train, y_train);\n",
    "\n",
    "best_model.best_estimator_.get_params()['clf']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-sellers",
   "metadata": {},
   "source": [
    "## Display Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "owned-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = best_model.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "critical-chemistry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=11, n_estimators=40)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view best model\n",
    "final_model = hyperparameters['clf']\n",
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "detailed-sampling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 11,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 40,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view best model's parameters\n",
    "final_params = best_model.best_estimator_['clf'].get_params()\n",
    "final_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "otherwise-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best model and apply get predictions for test set\n",
    "pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                 ('lr',     final_model)\n",
    "                ])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-shipping",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "administrative-insider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9078947368421053"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "critical-original",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  3],\n",
       "       [ 4, 41]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get confusion matrix\n",
    "confusion_matrix(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "architectural-hartford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9032258064516129"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get recall score for true 0's - no heart condition\n",
    "recall_score(y_test, y_pred, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "mineral-greece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9111111111111111"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get recall score for true 1's - heart condition\n",
    "\n",
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "trying-spray",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get precision score for false predictions\n",
    "precision_score(y_test, y_pred, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "professional-series",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9318181818181818"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get precision score for true predictions\n",
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-postcard",
   "metadata": {},
   "source": [
    "An accuracy score for a classification problem shows the percentage of accurate predictions. For this model, it is .907 which inidcates that is a good model, but other metrics should also be taken into account. \n",
    "\n",
    "A recall score shows that of true class labels how many were predicted correctly. This metric is a better indicator of how good your model is and lets you hone in on a label that may be more important to predict right. For this model, a recall score for no heart condition is .903, which means that of those who truely did not have a heart condition about 90.3% were accurately predicted to not have a heart condition. The recall score for heart condition is .911, which means that of those who truely did have a heart condition about 91.1% were accurately predicted to have a heart condition.\n",
    "\n",
    "On the other hand a precision score, shows the percentage of predictions that were correct. For no heart condition, this model's predictions were coorect 87.5% of the time. For heart conditions, it was 93.2%.\n",
    "\n",
    "In short, recall focuses on how many labels were predicted correctly, while prediction focuses on how many predictions were correct.\n",
    "\n",
    "A confusion matrix shows this information numerically, showing the count of False Negatives, True Negatives, False Positives, and True Positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-graphic",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-bleeding",
   "metadata": {},
   "source": [
    "The goal of this model was to be able to predict whether someone has a heart condition based on their demographic information and lab test results. In the end, our best model was a Random forest classifer made up of 40 descision trees who only considered a maximum 11 features when looking for a best split. The model's predictions were accurate 90.8% of the time. More specifically, no heart condition predictions were correct 87.5% of the time and heart conditions predictions were correct 93.2% of the time. The model also correctly identified those with a heart condition 91.1% of the time. \n",
    "\n",
    "Given that implications of a missed diagnosis, we would want to improve this model with a focus on being able to identify 100% of patients with a heart condition. That is, aim for a recall score for 1.0 for true heart conditions. A patient with a missed diagnosis may go on with out any treatment, potentially costing this person quality of life or even their life. \n",
    "\n",
    "This model can be used in both medical office and hospital settings by physicians, nurses, and other allied health professionals in order to identify those most at risk of having a heart condition. For example, in the ER, this model can be used to help the triage nurse assess the severity of a patient's condition. It can also be used by physicians as a guide to ordering tests to assess a patient's cardiovascular health.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-garage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-botswana",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-cooperative",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-orbit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-liabilities",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-chicken",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-mayor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
